{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP5ITN2uYHPl3lcrHlPiET5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulokuriki/agentic-researcher-flashcards/blob/main/agentic_researcher_flashcards.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ¤–ðŸ©º **AI on Scrubs**\n",
        "\n",
        "## **Agentic AI for Radiology Research & Education**\n",
        "\n",
        "Welcome to this interactive notebook on **Agentic AI**, where we explore how intelligent agents can collaborate autonomously to solve complex, domain-specific tasksâ€”in this case, within **radiology**.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸŽ¯ **What is Agentic AI?**\n",
        "\n",
        "Agentic AI refers to systems composed of autonomous agents, each with a specific role, that work together to accomplish multi-step objectives. These agents can:\n",
        "\n",
        "- Search for information\n",
        "- Analyze complex data\n",
        "- Generate structured outputs\n",
        "- Coordinate sequential workflows\n",
        "\n",
        "This framework is especially powerful in **medical research, education, and automation**.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ› ï¸ Tasks Weâ€™ll Perform in This Notebook:\n",
        "\n",
        "### ðŸ“š **Part 1: Literature Review with Agentic AI**\n",
        "\n",
        "We will use a team of intelligent agents to:\n",
        "- ðŸ” Search PubMed for recent and relevant studies on a selected radiology topic.\n",
        "- ðŸ§ª Analyze each study in depth (methods, results, limitations).\n",
        "- ðŸ§  Synthesize a **comprehensive literature review** with insights and references.\n",
        "- ðŸ’¾ Export the result to a structured Word document.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ§¾ **Part 2: Flashcard Generation for Board Review**\n",
        "\n",
        "Another agentic crew will:\n",
        "- ðŸ”Ž Search Radiopaedia for high-yield educational articles on a radiology topic.\n",
        "- ðŸ“‹ Extract board-relevant information from each article.\n",
        "- â“ Generate 10â€“15 **high-quality flashcards** in Q&A format.\n",
        "- ðŸ“½ï¸ Compile the flashcards into a downloadable PowerPoint deck.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "H048my0mpg_I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ” **Before We Start:** Setting Up API Keys\n",
        "\n",
        "This notebook uses **Agentic AI** to automate radiology research and education workflows. To function properly, it requires **two API keys**:\n",
        "\n",
        "1. [**APIFY API Token**](https://apify.com/) â€“ for intelligent web browsing and scraping from sites like PubMed and Radiopaedia  \n",
        "2. [**Gemini API Key**](https://aistudio.google.com/app/apikey) â€“ for running the language model that powers your AI agents  \n",
        "\n",
        "> ðŸ”’ These keys are used **locally only** and are **never stored or shared**.\n",
        "\n",
        "---\n",
        "\n",
        "### â“ Why These Keys?\n",
        "\n",
        "- **APIFY** lets your agents simulate browser sessions to extract full article content from the web  \n",
        "- **Gemini** provides the LLM intelligence for reasoning, summarizing, analyzing, and generating content\n",
        "\n",
        "---\n",
        "\n",
        "### âš™ï¸ Get Your **APIFY API Token**\n",
        "\n",
        "1. Go to [Apify Console](https://console.apify.com/)\n",
        "2. Log in or sign up  \n",
        "3. Click **Settings** â†’ **API & Integrations**  \n",
        "4. Copy your **Personal API Token**  \n",
        "5. Store it somewhere safe  \n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ¤– Get Your **Gemini API Key**\n",
        "\n",
        "1. Visit [Google AI Studio](https://aistudio.google.com/app/apikey)  \n",
        "2. Log in with your Google account  \n",
        "3. Click **Get API Key** and agree to terms  \n",
        "4. Copy the generated key  \n",
        "\n",
        "> ðŸ’¡ Free-tier usage should be enough for this notebook.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ” Use the Keys in the Notebook\n",
        "\n",
        "Paste your keys when prompted:\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "yx2YfVwfo_yO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“¦ Install Required Packages\n",
        "\n",
        "Run the following cell to install all necessary libraries for this notebook.\n",
        "\n",
        "> âš ï¸ You may see a long list of packages and dependency warnings â€” this is expected.  \n",
        "> ðŸ”„ After installation, **restart the notebook** to apply changes. This is normal for Jupyter.\n"
      ],
      "metadata": {
        "id": "c_KZ5Hnos7Rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install crewai[tools] langchain-apify python-docx python-pptx markdown2 langchain-google-genai"
      ],
      "metadata": {
        "id": "0OW9FEIweyRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ”‘ Enter Your API Keys\n",
        "\n",
        "Paste the API keys you created earlier when prompted below. Theyâ€™ll be securely collected (not displayed or stored).\n",
        "\n",
        "> ðŸ”’ These inputs are hidden for your privacy."
      ],
      "metadata": {
        "id": "87_Iy6DTtPlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "\n",
        "# Securely collect APIFY_API_TOKEN\n",
        "APIFY_API_TOKEN = getpass.getpass(\"Enter your APIFY API Token: \")\n",
        "\n",
        "# Securely collect GEMINI_API_KEY\n",
        "GEMINI_API_KEY = getpass.getpass(\"Enter your GEMINI API Key: \")\n",
        "\n",
        "# Optional: Confirm keys are set (use with caution)\n",
        "print(\"API keys collected securely.\")\n"
      ],
      "metadata": {
        "id": "GogbJ8SfhQth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“š Import Libraries & Set API Keys\n",
        "\n",
        "Import all required libraries and set your API keys for use."
      ],
      "metadata": {
        "id": "piC1u9BmtbhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# ðŸ“¦ Import necessary libraries\n",
        "# --------------------------\n",
        "\n",
        "import warnings\n",
        "\n",
        "# Suppress all warnings globally (e.g., Pydantic deprecation messages)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import random\n",
        "import json\n",
        "\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "from crewai import Agent, Task, Crew, Process, LLM\n",
        "#from langchain.agents import Tool\n",
        "from crewai.tools import tool\n",
        "from crewai_tools import ApifyActorsTool\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "import markdown\n",
        "from bs4 import BeautifulSoup\n",
        "from docx import Document\n",
        "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
        "from docx.shared import Pt, RGBColor as DocxRGBColor\n",
        "from docx.oxml.ns import qn\n",
        "\n",
        "from pptx import Presentation\n",
        "from pptx.util import Inches, Pt\n",
        "from pptx.dml.color import RGBColor as PptxRGBColor\n",
        "\n",
        "# --------------------------\n",
        "# ðŸ” Set API Keys securely\n",
        "# --------------------------\n",
        "\n",
        "# These should already be defined using getpass earlier in the notebook\n",
        "# Avoid hardcoding sensitive information\n",
        "os.environ[\"APIFY_API_TOKEN\"] = APIFY_API_TOKEN\n",
        "os.environ[\"GEMINI_API_KEY\"] = GEMINI_API_KEY\n",
        "\n",
        "# --------------------------\n",
        "# âš™ï¸ Define system constants\n",
        "# --------------------------\n",
        "\n",
        "# Max requests per minute (to respect API rate limits)\n",
        "MAX_RPM = 20\n",
        "\n",
        "# Max retry attempts for failed API calls\n",
        "MAX_RETRY_LIMIT = 10\n"
      ],
      "metadata": {
        "id": "St_5JA-ofOAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ§° Utility Functions\n",
        "\n",
        "Helper functions to display markdown, save Word docs, and generate flashcard PowerPoints."
      ],
      "metadata": {
        "id": "4N7KoEZ9tpov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Display and Export Utilities ===\n",
        "\n",
        "def display_markdown(text):\n",
        "    \"\"\"\n",
        "    This function is meant for Jupyter notebooks.\n",
        "    In a regular Python script, you can't use this directly.\n",
        "\n",
        "    For Jupyter notebooks:\n",
        "    from IPython.display import Markdown, display\n",
        "    display(Markdown(text))\n",
        "    \"\"\"\n",
        "    try:\n",
        "        from IPython.display import Markdown, display\n",
        "        display(Markdown(text))\n",
        "    except ImportError:\n",
        "        print(\"IPython not available. This function is intended for Jupyter notebooks only.\")\n",
        "        print(\"Preview of markdown:\\n\", text)\n",
        "\n",
        "def save_to_word(markdown_text, filename):\n",
        "    \"\"\"\n",
        "    Convert markdown text to a Word document with proper formatting.\n",
        "\n",
        "    Parameters:\n",
        "    markdown_text (str): Markdown formatted text\n",
        "    filename (str): Output filename (without extension)\n",
        "\n",
        "    Returns:\n",
        "    None: Saves the document to disk\n",
        "    \"\"\"\n",
        "    # Convert markdown to HTML with extensions\n",
        "    html = markdown.markdown(markdown_text, extensions=['tables', 'fenced_code'])\n",
        "\n",
        "    # Parse HTML using BeautifulSoup\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "    # Create a Word document\n",
        "    doc = Document()\n",
        "\n",
        "    # Process the HTML elements recursively\n",
        "    process_elements(soup, doc)\n",
        "\n",
        "    # Save to Word file\n",
        "    doc.save(f\"{filename}.docx\")\n",
        "    print(f\"âœ… Saved as '{filename}.docx'\")\n",
        "\n",
        "def process_elements(parent, doc, current_paragraph=None):\n",
        "    \"\"\"\n",
        "    Recursively process HTML elements and add them to the Word document.\n",
        "\n",
        "    Parameters:\n",
        "    parent: BeautifulSoup element or NavigableString\n",
        "    doc: Document object\n",
        "    current_paragraph: Optional paragraph object for inline elements\n",
        "\n",
        "    Returns:\n",
        "    None: Modifies the document in place\n",
        "    \"\"\"\n",
        "    # If the parent is a string (NavigableString), just add it to the current paragraph\n",
        "    if isinstance(parent, str) or not hasattr(parent, 'children'):\n",
        "        if current_paragraph:\n",
        "            current_paragraph.add_run(str(parent))\n",
        "        else:\n",
        "            doc.add_paragraph(str(parent))\n",
        "        return\n",
        "\n",
        "    # Process all children\n",
        "    for element in parent.children:\n",
        "        if element.name is None:  # This is a text node\n",
        "            if current_paragraph and str(element).strip():\n",
        "                current_paragraph.add_run(str(element))\n",
        "            elif str(element).strip():\n",
        "                current_paragraph = doc.add_paragraph(str(element))\n",
        "            continue\n",
        "\n",
        "        if element.name == 'h1':\n",
        "            doc.add_heading(element.get_text(), level=1)\n",
        "        elif element.name == 'h2':\n",
        "            doc.add_heading(element.get_text(), level=2)\n",
        "        elif element.name == 'h3':\n",
        "            doc.add_heading(element.get_text(), level=3)\n",
        "        elif element.name == 'p':\n",
        "            # Create a new paragraph\n",
        "            p = doc.add_paragraph()\n",
        "            p.alignment = WD_PARAGRAPH_ALIGNMENT.LEFT\n",
        "            # Process all children of the paragraph\n",
        "            process_elements(element, doc, p)\n",
        "        elif element.name == 'strong' or element.name == 'b':\n",
        "            # If we're in a paragraph, add a bold run\n",
        "            if current_paragraph:\n",
        "                run = current_paragraph.add_run(element.get_text())\n",
        "                run.bold = True\n",
        "            else:\n",
        "                p = doc.add_paragraph()\n",
        "                run = p.add_run(element.get_text())\n",
        "                run.bold = True\n",
        "        elif element.name == 'em' or element.name == 'i':\n",
        "            # If we're in a paragraph, add an italic run\n",
        "            if current_paragraph:\n",
        "                run = current_paragraph.add_run(element.get_text())\n",
        "                run.italic = True\n",
        "            else:\n",
        "                p = doc.add_paragraph()\n",
        "                run = p.add_run(element.get_text())\n",
        "                run.italic = True\n",
        "        elif element.name == 'ul':\n",
        "            for li in element.find_all('li', recursive=False):\n",
        "                p = doc.add_paragraph(style='List Bullet')\n",
        "                process_elements(li, doc, p)\n",
        "        elif element.name == 'ol':\n",
        "            for index, li in enumerate(element.find_all('li', recursive=False)):\n",
        "                p = doc.add_paragraph(style='List Number')\n",
        "                process_elements(li, doc, p)\n",
        "        elif element.name == 'hr':\n",
        "            doc.add_paragraph('_' * 50)\n",
        "        elif element.name == 'a':\n",
        "            if current_paragraph:\n",
        "                run = current_paragraph.add_run(element.get_text())\n",
        "                run.underline = True\n",
        "                #run.font.color.rgb = RGBColor(0, 0, 255)\n",
        "                run.font.color.rgb = DocxRGBColor(0x00, 0x00, 0xFF)\n",
        "                # Add hyperlink\n",
        "                if 'href' in element.attrs:\n",
        "                    run.hyperlink = element['href']\n",
        "            else:\n",
        "                p = doc.add_paragraph()\n",
        "                run = p.add_run(element.get_text())\n",
        "                run.underline = True\n",
        "                #run.font.color.rgb = RGBColor(0, 0, 255)\n",
        "                run.font.color.rgb = DocxRGBColor(0x00, 0x00, 0xFF)\n",
        "                # Add hyperlink\n",
        "                if 'href' in element.attrs:\n",
        "                    run.hyperlink = element['href']\n",
        "        elif element.name == 'blockquote':\n",
        "            p = doc.add_paragraph()\n",
        "            p.style = 'Quote'\n",
        "            process_elements(element, doc, p)\n",
        "        else:\n",
        "            # Recursively process other elements\n",
        "            process_elements(element, doc, current_paragraph)\n",
        "\n",
        "def create_flashcard_ppt(json_file_path, topic):\n",
        "    \"\"\"\n",
        "    Create a PowerPoint presentation from flashcard data in JSON format.\n",
        "\n",
        "    Args:\n",
        "        json_file_path (str): Path to the JSON file containing flashcards\n",
        "\n",
        "    Returns:\n",
        "        str: Path to the created PowerPoint file\n",
        "    \"\"\"\n",
        "    clean_topic = topic.replace(\" \", \"_\").lower()\n",
        "    output_pptx_name = f\"{clean_topic}_flashcards.pptx\"\n",
        "\n",
        "    # Load the flashcards from JSON\n",
        "    with open(json_file_path, 'r') as f:\n",
        "        flashcards = json.load(f)\n",
        "\n",
        "    # Create a presentation\n",
        "    prs = Presentation()\n",
        "\n",
        "    # Define slide layouts\n",
        "    title_layout = prs.slide_layouts[0]  # Title Slide\n",
        "    content_layout = prs.slide_layouts[1]  # Title and Content\n",
        "\n",
        "    # Create title slide\n",
        "    title_slide = prs.slides.add_slide(title_layout)\n",
        "    title = title_slide.shapes.title\n",
        "    subtitle = title_slide.placeholders[1]\n",
        "\n",
        "    title.text = f\"Radiology Flashcards\"\n",
        "    subtitle.text = f\"Topic: {topic.title()}\\n\\nCore Exam Preparation\"\n",
        "\n",
        "    # Add instructions slide\n",
        "    instruction_slide = prs.slides.add_slide(content_layout)\n",
        "    instruction_slide.shapes.title.text = \"How to Use These Flashcards\"\n",
        "    content = instruction_slide.placeholders[1]\n",
        "    content.text = (\n",
        "        \"1. Each flashcard consists of two slides: a Question followed by an Answer\\n\\n\"\n",
        "        \"2. Try to answer the question before moving to the next slide\\n\\n\"\n",
        "        \"3. These cards are designed to reinforce critical concepts for Core Exam\\n\\n\"\n",
        "    )\n",
        "\n",
        "    # Create flashcard slides\n",
        "    for i, card in enumerate(flashcards, 1):\n",
        "        # Question slide\n",
        "        q_slide = prs.slides.add_slide(content_layout)\n",
        "        q_slide.shapes.title.text = f\"Question {i}\"\n",
        "        q_content = q_slide.placeholders[1]\n",
        "        q_content.text = card['question']\n",
        "\n",
        "        # Style question text\n",
        "        for paragraph in q_content.text_frame.paragraphs:\n",
        "            paragraph.alignment = 1  # Center alignment\n",
        "            for run in paragraph.runs:\n",
        "                run.font.size = Pt(28)\n",
        "                run.font.bold = True\n",
        "\n",
        "        # Answer slide\n",
        "        a_slide = prs.slides.add_slide(content_layout)\n",
        "        a_slide.shapes.title.text = f\"Answer {i}\"\n",
        "        a_content = a_slide.placeholders[1]\n",
        "        a_content.text = card['answer']\n",
        "\n",
        "        # Style answer text\n",
        "        for paragraph in a_content.text_frame.paragraphs:\n",
        "            for run in paragraph.runs:\n",
        "                run.font.size = Pt(24)\n",
        "\n",
        "    # Save the presentation\n",
        "    prs.save(output_pptx_name)\n",
        "    print(f\"PowerPoint created: {output_pptx_name}\")\n",
        "\n",
        "\n",
        "\n",
        "# Save results to a JSON file\n",
        "def extract_json_from_output(output_text):\n",
        "    \"\"\"\n",
        "    Attempt to extract a JSON array of flashcards from raw agent output.\n",
        "\n",
        "    Args:\n",
        "        output_text (str): Raw string containing potential JSON.\n",
        "\n",
        "    Returns:\n",
        "        list: Parsed list of flashcards, or empty list if none found.\n",
        "    \"\"\"\n",
        "    # Look for JSON array pattern\n",
        "    json_pattern = r'\\[\\s*{\\s*\"question\":.+\\}\\s*\\]'\n",
        "    match = re.search(json_pattern, output_text, re.DOTALL)\n",
        "\n",
        "    if match:\n",
        "        try:\n",
        "            # Try parsing the matched JSON\n",
        "            json_text = match.group(0)\n",
        "            return json.loads(json_text)\n",
        "        except json.JSONDecodeError:\n",
        "            pass\n",
        "\n",
        "    # Fallback: Try to extract based on code blocks\n",
        "    json_block_pattern = r'```json\\s*([\\s\\S]*?)\\s*```'\n",
        "    block_match = re.search(json_block_pattern, output_text)\n",
        "\n",
        "    if block_match:\n",
        "        try:\n",
        "            return json.loads(block_match.group(1))\n",
        "        except json.JSONDecodeError:\n",
        "            pass\n",
        "\n",
        "    # Return empty list if no valid JSON found\n",
        "    return []\n",
        "\n",
        "# === Initialize Web Browser Tool and LLM ===\n",
        "\n",
        "# Web scraping tool powered by Apify for structured markdown content\n",
        "rag_browser = ApifyActorsTool(\n",
        "    actor_name=\"apify/rag-web-browser\",\n",
        "    actor_config={\n",
        "        \"outputFormats\": [\"markdown\"],\n",
        "        \"requestTimeoutSecs\": 45,\n",
        "        \"scrapingTool\": \"browser-playwright\",\n",
        "        \"removeCookieWarnings\": True\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "# Google Gemini LLM instance for reasoning tasks\n",
        "llm = LLM(\"gemini/gemini-2.0-flash-lite\")\n",
        "\n",
        "# âœ… Confirmation message\n",
        "print(\"Utility functions loaded successfully ðŸ’ª\")"
      ],
      "metadata": {
        "id": "CHesBlAxkv14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ” Literature Review\n",
        "\n",
        "### âœ… Overview\n",
        "A **three-agent pipeline** will be activated to conduct a **comprehensive literature review** on the radiology topic you want:\n",
        "\n",
        "### ðŸ§  Agents Involved:\n",
        "1. **PubMed Researcher**\n",
        "   - Searches PubMed for recent and relevant studies.\n",
        "   - Returns at least 3 articles with full bibliographic details.\n",
        "\n",
        "2. **Medical Research Analyst**\n",
        "   - Retrieves and analyzes each article.\n",
        "   - Summarizes objectives, methods, findings, limitations, and relevance.\n",
        "\n",
        "3. **Research Synthesizer**\n",
        "   - Integrates all analyses into a structured literature review.\n",
        "   - Highlights current knowledge, gaps, contradictions, and future directions.\n",
        "\n",
        "### ðŸ“„ Outputs:\n",
        "- A comprehensive **Markdown-formatted literature review** displayed in the notebook.\n",
        "- A **Word document (.docx)** version of the review saved locally as:\n",
        "  ```\n",
        "  Literature_Review.docx\n",
        "  ```\n"
      ],
      "metadata": {
        "id": "k1xUDMG8otCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------------\n",
        "# Tools\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "@tool(\"GetFullArticle\")\n",
        "def get_full_article(url: str) -> str:\n",
        "    \"\"\"\n",
        "    Retrieve the full content of an article from a given URL.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL of the article to retrieve.\n",
        "\n",
        "    Returns:\n",
        "        str: The full content of the article in markdown format, or an error message if retrieval fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Validate URL format\n",
        "        if not url.startswith(\"http\"):\n",
        "            return \"Please provide a valid URL starting with http:// or https://\"\n",
        "\n",
        "        # Fetch content using Apify's RAG Web Browser\n",
        "        article_content = rag_browser.run(\n",
        "            run_input={\"query\": url, \"maxResults\": 1}\n",
        "            )\n",
        "\n",
        "        return article_content\n",
        "    except Exception as e:\n",
        "        # Handle and return the error message\n",
        "        return f\"Error retrieving article content: {str(e)}\"\n",
        "\n",
        "\n",
        "@tool(\"PubMedSearch\")\n",
        "def search_pubmed(query: str, max_results: int = 5) -> str:\n",
        "    \"\"\"\n",
        "    Search PubMed for medical research articles using Apify's RAG Web Browser.\n",
        "\n",
        "    Args:\n",
        "        query (str): The search term to query PubMed.\n",
        "        max_results (int): Maximum number of search results to return (default is 5).\n",
        "\n",
        "    Returns:\n",
        "        str: A list of search results in markdown format, or an error message if the search fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Construct the PubMed-specific search query\n",
        "        pubmed_query = f\"site:pubmed.ncbi.nlm.nih.gov {query} after:2024\"\n",
        "\n",
        "        # Execute the search using Apify's RAG Web Browser\n",
        "        results = rag_browser.run(run_input={\n",
        "            \"query\": pubmed_query,\n",
        "            \"maxResults\": max_results\n",
        "        })\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        # Handle and return the error message\n",
        "        return f\"Error searching PubMed: {str(e)}\"\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# PubMed Researcher Agent\n",
        "# -------------------------------------------------------------------\n",
        "pubmed_researcher = Agent(\n",
        "    role=\"PubMed Researcher\",\n",
        "    goal=\"Locate and compile a curated list of current, pertinent studies on [RADIOLOGY_TOPIC], focusing on those that offer significant contributions to the field.\",\n",
        "    backstory=\"\"\"You are an expert medical research specialist with deep knowledge of radiology.\n",
        "You excel at navigating PubMed to find the most relevant and recent research for any given radiology topic,\n",
        "emphasizing high-impact and high-quality studies. You have developed advanced strategies for searching\n",
        "PubMed over many years, quickly filtering out low-impact or outdated articles and homing in on\n",
        "publications that meaningfully advance understanding and clinical practice in radiology.\"\"\",\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    tools=[search_pubmed],\n",
        "    llm=llm,\n",
        "    max_rpm=MAX_RPM,\n",
        "    max_retry_limit=MAX_RETRY_LIMIT\n",
        ")\n",
        "\n",
        "pubmed_search_task = Task(\n",
        "    description=\"\"\"\n",
        "1. Conduct a targeted PubMed search on [RADIOLOGY_TOPIC].\n",
        "2. Identify at least 3 recent, high-quality papers.\n",
        "3. For each paper, provide:\n",
        "   - Title\n",
        "   - Authors\n",
        "   - Publication date\n",
        "   - Journal\n",
        "   - URL or citation link\n",
        "4. Ensure the curated list includes studies that collectively reflect the major\n",
        "   developments and perspectives on [RADIOLOGY_TOPIC].\n",
        "\"\"\",\n",
        "    agent=pubmed_researcher,\n",
        "    expected_output=\"A list of at least 3 relevant research articles with full bibliographic details and URLs.\"\n",
        ")\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Medical Research Analyst Agent\n",
        "# -------------------------------------------------------------------\n",
        "pubmed_analyst = Agent(\n",
        "    role=\"Medical Research Analyst\",\n",
        "    goal=\"Deliver structured, in-depth analyses of each retrieved article, focusing on the objectives, methods, results, conclusions, and an assessment of each studyâ€™s reliability and importance.\",\n",
        "    backstory=\"\"\"You are a medical research analyst with specialized expertise in radiology.\n",
        "You excel at dissecting and evaluating research publicationsâ€”particularly their methods,\n",
        "results, and overall quality. You have a keen eye for detail and extensive background\n",
        "in research methodology, making you adept at unpacking complex study designs and interpreting\n",
        "data rigorously.\"\"\",\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    tools=[get_full_article],\n",
        "    llm=llm,\n",
        "    max_rpm=MAX_RPM,\n",
        "    max_retry_limit=MAX_RETRY_LIMIT\n",
        ")\n",
        "\n",
        "pubmed_analysis_task = Task(\n",
        "    description=\"\"\"\n",
        "For each paper provided by the PubMed Researcher:\n",
        "1. Try to retrieve the abstract.\n",
        "2. Identify and summarize:\n",
        "   - The research question or objective\n",
        "   - Study design and methodology\n",
        "   - Key findings or results\n",
        "   - Limitations acknowledged by the authors\n",
        "   - Conclusions and implications for the field\n",
        "3. Offer a brief assessment of the paperâ€™s overall quality, significance, and relevance.\n",
        "4. Present the analysis in a structured, consistent format to facilitate subsequent synthesis.\n",
        "\"\"\",\n",
        "    agent=pubmed_analyst,\n",
        "    expected_output=\"A detailed yet concise analysis of each research paper, capturing its core contributions, strengths, and weaknesses.\"\n",
        ")\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Research Synthesizer Agent\n",
        "# -------------------------------------------------------------------\n",
        "pubmed_synthesizer = Agent(\n",
        "    role=\"Research Synthesizer\",\n",
        "    goal=\"Merge the analyses from all reviewed papers into a clear, comprehensive literature review that illuminates the current state of knowledge on [RADIOLOGY_TOPIC] and guides further research.\",\n",
        "    backstory=\"\"\"You are a research synthesis expert specializing in radiology.\n",
        "You excel at integrating findings from multiple studies into a cohesive narrative that clarifies\n",
        "current understanding, notes contradictions or gaps, and suggests directions for future investigation.\n",
        "You have years of experience writing academic and clinical reviews and can reconcile divergent findings\n",
        "by comparing methodologies and study populations.\"\"\",\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    llm=llm,\n",
        "    max_rpm=MAX_RPM,\n",
        "    max_retry_limit=MAX_RETRY_LIMIT\n",
        ")\n",
        "\n",
        "pubmed_synthesis_task = Task(\n",
        "    description=\"\"\"\n",
        "Based on the analyses provided:\n",
        "1. Integrate findings: Compare and combine the key points from each analysis to form a unified overview of the research landscape on [RADIOLOGY_TOPIC].\n",
        "2. Identify common themes and contradictions: Highlight consistent results, discuss conflicting data, and propose potential reasons for disparities.\n",
        "3. Evaluate overall strength of evidence: Note methodological limitations or areas lacking robust data, explaining how these affect the validity of conclusions.\n",
        "4. Summarize current knowledge: Clearly state what is broadly accepted in the field, as well as any ongoing controversies.\n",
        "5. Highlight gaps and future directions: Suggest where additional or alternative research might be warranted and what questions remain unanswered.\n",
        "6. Provide a bibliography: List all referenced studies in a consistent citation format.\n",
        "7. Produce a structured literature review: Present a concise yet thorough synthesis that can serve as a stand-alone overview of the topic.\n",
        "\"\"\",\n",
        "    agent=pubmed_synthesizer,\n",
        "    expected_output=\"\"\"\n",
        "A well-organized, comprehensive literature review on [RADIOLOGY_TOPIC] that clearly integrates\n",
        "all analyzed studies and includes suggestions for future research, along with a bibliography\n",
        "of all cited papers.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "def generate_literature_review(topic):\n",
        "    # Update tasks with the specific topic\n",
        "    pubmed_search_task.description = pubmed_search_task.description.replace(\"[RADIOLOGY_TOPIC]\", topic)\n",
        "    pubmed_synthesis_task.description = pubmed_synthesis_task.description.replace(\"[RADIOLOGY_TOPIC]\", topic)\n",
        "\n",
        "    # Create the crew\n",
        "    pubmed_review_crew = Crew(\n",
        "        agents=[pubmed_researcher, pubmed_analyst, pubmed_synthesizer],\n",
        "        tasks=[pubmed_search_task, pubmed_analysis_task, pubmed_synthesis_task],\n",
        "        process=Process.sequential,\n",
        "        max_rpm=MAX_RPM,\n",
        "        max_retry_limit=MAX_RETRY_LIMIT,\n",
        "        output_log_file=True,\n",
        "        verbose=True)\n",
        "\n",
        "    # Execute the crew\n",
        "    literature_review = pubmed_review_crew.kickoff()\n",
        "\n",
        "    # Display in Jupyter Notebook\n",
        "    display_markdown(literature_review.raw)\n",
        "\n",
        "    # Save to Word\n",
        "    save_to_word(literature_review.raw, \"Literature_Review\")\n",
        "\n",
        "    print('-'*50)\n",
        "    print(\"\\nLiterature Review is complete.\\n\")\n",
        "    print(\"<<<--- Open the left tab and look for the Literature_Review.doc file.\\n\")\n",
        "    print('-'*50)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4lpgIT7cf7tI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ§  Time to run the Agentic Literature Reviewer\n",
        "\n",
        "This section will launch a team of three AI agents to generate a structured literature review on a radiology topic of your choice.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ” Choose Your Topic:\n",
        "Update the `topic` variable with **any radiology topic** you want to explore:\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ“ Outputs:\n",
        "- ðŸ“„ Review displayed directly in the notebook\n",
        "- ðŸ’¾ Automatically saved as a Word document: `Literature_Review.docx`\n"
      ],
      "metadata": {
        "id": "Jdgi4Ems2DdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with your radiology topic of interest\n",
        "topic = \"artificial intelligence in breast cancer\"\n",
        "\n",
        "# Run the literature review pipeline\n",
        "generate_literature_review(topic)\n"
      ],
      "metadata": {
        "id": "0TXEYLzxo23V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“š Agentic Flashcard Generator\n",
        "\n",
        "### âœ… Overview\n",
        "Another **three-agent pipeline** will run to produce **board-style flashcards** for radiology education.\n",
        "\n",
        "### ðŸ§  Agents Involved:\n",
        "1. **Radiopaedia Researcher**\n",
        "   - Searches Radiopaedia for high-yield educational articles.\n",
        "   - Returns 5+ curated links with brief justifications.\n",
        "\n",
        "2. **Radiology Content Extractor**\n",
        "   - Extracts structured, board-relevant content from the articles.\n",
        "   - Focuses on:\n",
        "     - Pathology\n",
        "     - Imaging features\n",
        "     - Differential diagnosis\n",
        "     - Clinical presentation\n",
        "     - Epidemiology\n",
        "\n",
        "3. **Flashcard Generator**\n",
        "   - Creates 10â€“15 Q&A flashcards.\n",
        "   - Formats output as a valid JSON array.\n",
        "\n",
        "### ðŸ“ Output:\n",
        "- Flashcards compiled into a **PowerPoint (.pptx)** presentation:\n",
        "  ```\n",
        "  topic_flashcards.pptx\n",
        "  ```\n"
      ],
      "metadata": {
        "id": "f7Q6MNQEocys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------------\n",
        "# Tools\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "@tool(\"search_radiopaedia\")\n",
        "def search_radiopaedia(query: str, max_results: int = 5) -> str:\n",
        "    \"\"\"\n",
        "    Search Radiopaedia for radiology-related articles using Apify's RAG Web Browser.\n",
        "    Args:\n",
        "        query (str): The search term to query Radiopaedia.\n",
        "        max_results (int): Maximum number of search results to return (default is 5).\n",
        "    Returns:\n",
        "        str: A list of search results in markdown format, or an error message if the search fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Construct the Radiopaedia-specific search query\n",
        "        radiopaedia_query = f\"site:radiopaedia.org {query}\"\n",
        "        # Execute the search using Apify's RAG Web Browser\n",
        "        results = rag_browser.run(run_input={\n",
        "            \"query\": radiopaedia_query,\n",
        "            \"maxResults\": max_results\n",
        "        })\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        # Handle and return the error message\n",
        "        return f\"Error searching Radiopaedia: {str(e)}\"\n",
        "\n",
        "@tool(\"get_full_article\")\n",
        "def get_full_article(url: str) -> str:\n",
        "    \"\"\"\n",
        "    Retrieve the full content of an article from a given URL.\n",
        "    Args:\n",
        "        url (str): The URL of the article to retrieve.\n",
        "    Returns:\n",
        "        str: The full content of the article in markdown format, or an error message if retrieval fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Validate URL format\n",
        "        if not url.startswith(\"http\"):\n",
        "            return \"Please provide a valid URL starting with http:// or https://\"\n",
        "        # Fetch content using Apify's RAG Web Browser\n",
        "        article_content = rag_browser.run(run_input={\n",
        "            \"query\": url,\n",
        "            \"maxResults\": 1\n",
        "        })\n",
        "        return article_content\n",
        "    except Exception as e:\n",
        "        # Handle and return the error message\n",
        "        return f\"Error retrieving article content: {str(e)}\"\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Radiopaedia Researcher Agent\n",
        "# -------------------------------------------------------------------\n",
        "radiopaedia_researcher = Agent(\n",
        "    role=\"Radiopaedia Researcher\",\n",
        "    goal=\"Locate and compile a curated list of pertinent Radiopaedia articles on [RADIOLOGY_TOPIC], focusing on those that offer significant educational value for radiology board exam preparation.\",\n",
        "    backstory=\"\"\"You are an expert radiology educator with deep knowledge of board exam requirements.\n",
        "You excel at navigating Radiopaedia to find the most relevant articles for any given radiology topic,\n",
        "emphasizing high-educational-value articles with clear descriptions of imaging findings, differential\n",
        "diagnoses, and clinical correlations that are commonly tested on board exams.\"\"\",\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    tools=[search_radiopaedia],\n",
        "    llm=llm,\n",
        "    max_rpm=MAX_RPM,\n",
        "    max_retry_limit=MAX_RETRY_LIMIT\n",
        ")\n",
        "\n",
        "radiopaedia_search_task = Task(\n",
        "    description=\"\"\"\n",
        "1. Conduct a targeted Radiopaedia search on [RADIOLOGY_TOPIC].\n",
        "2. Identify at least 5 high-quality educational articles.\n",
        "3. For each article, provide:\n",
        "   - Title\n",
        "   - URL\n",
        "   - Brief description of why it's valuable for board exam preparation\n",
        "4. Ensure the curated list includes articles that collectively cover the major\n",
        "   aspects of [RADIOLOGY_TOPIC] relevant to board exams.\n",
        "\"\"\",\n",
        "    agent=radiopaedia_researcher,\n",
        "    expected_output=\"A list of at least 5 relevant Radiopaedia articles with URLs and brief descriptions of their educational value.\"\n",
        ")\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Content Extractor Agent\n",
        "# -------------------------------------------------------------------\n",
        "content_extractor = Agent(\n",
        "    role=\"Radiology Content Extractor\",\n",
        "    goal=\"Extract comprehensive educational content from Radiopaedia articles to create high-quality board review materials.\",\n",
        "    backstory=\"\"\"You are a specialized radiology educator who excels at identifying and extracting\n",
        "board-relevant content from educational resources. You know exactly what information is most\n",
        "likely to appear on board exams and how to organize it effectively for learning. You have\n",
        "years of experience preparing residents for their board exams and know what level of detail\n",
        "is appropriate.\"\"\",\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    tools=[get_full_article],\n",
        "    llm=llm,\n",
        "    max_rpm=MAX_RPM,\n",
        "    max_retry_limit=MAX_RETRY_LIMIT\n",
        ")\n",
        "\n",
        "content_extraction_task = Task(\n",
        "    description=\"\"\"\n",
        "For each Radiopaedia article provided by the researcher:\n",
        "1. Retrieve the full article content using the URL.\n",
        "2. Extract key educational information relevant to board exams:\n",
        "   - Pathology name and classification\n",
        "   - Key imaging findings (for different modalities if available)\n",
        "   - Epidemiology and demographics\n",
        "   - Clinical presentation\n",
        "   - Differential diagnoses\n",
        "   - Treatment and management (if available)\n",
        "3. Organize the extracted information in a clear, structured format.\n",
        "\"\"\",\n",
        "    agent=content_extractor,\n",
        "    expected_output=\"Organized, board-relevant content extracted from each Radiopaedia article.\"\n",
        ")\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Flashcard Generator Agent\n",
        "# -------------------------------------------------------------------\n",
        "flashcard_generator = Agent(\n",
        "    role=\"Radiology Flashcard Generator\",\n",
        "    goal=\"Create high-quality question-answer pairs for radiology board exam preparation.\",\n",
        "    backstory=\"\"\"You are an expert in radiology education who specializes in creating effective\n",
        "board review materials. You have a deep understanding of what makes a good flashcard - clear,\n",
        "focused questions with comprehensive yet concise answers. You know exactly what information\n",
        "is most commonly tested on board exams and how to frame questions to enhance learning and\n",
        "retention. Your flashcards are consistently rated as the most helpful study resources by\n",
        "radiology residents.\"\"\",\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    llm=llm,\n",
        "    max_rpm=MAX_RPM,\n",
        "    max_retry_limit=MAX_RETRY_LIMIT\n",
        ")\n",
        "\n",
        "flashcard_generation_task = Task(\n",
        "    description=\"\"\"\n",
        "Based on the extracted content from Radiopaedia articles:\n",
        "1. Create 10-15 high-quality question-answer pairs suitable for board exam preparation on [RADIOLOGY_TOPIC].\n",
        "2. For each question-answer pair:\n",
        "   - Formulate a clear, specific question that tests understanding of key concepts\n",
        "   - Provide a comprehensive yet concise answer that includes the most board-relevant information\n",
        "   - Ensure questions cover different aspects (imaging findings, differential diagnoses, epidemiology, etc.)\n",
        "3. Format the output as a valid JSON array with each flashcard as an object with \"question\" and \"answer\" fields:\n",
        "   ```json\n",
        "   [\n",
        "     {\n",
        "       \"question\": \"What are the classic MRI findings of pilocytic astrocytoma?\",\n",
        "       \"answer\": \"Cystic lesion with enhancing mural nodule; T1 hypointense, T2 hyperintense; avid enhancement of solid component; commonly in cerebellum, optic pathways, brain stem.\"\n",
        "     },\n",
        "     {\n",
        "       \"question\": \"...\",\n",
        "       \"answer\": \"...\"\n",
        "     }\n",
        "   ]\n",
        "   ```\n",
        "4. Ensure the JSON is properly formatted and valid.\n",
        "\"\"\",\n",
        "    agent=flashcard_generator,\n",
        "    expected_output=\"A JSON array of 10-15 high-quality question-answer pairs suitable for radiology board exam preparation.\"\n",
        ")\n",
        "\n",
        "\n",
        "def generate_flashcards(topic):\n",
        "    # Update tasks with the specific topic\n",
        "    radiopaedia_search_task.description = radiopaedia_search_task.description.replace(\"[RADIOLOGY_TOPIC]\", topic)\n",
        "    flashcard_generation_task.description = flashcard_generation_task.description.replace(\"[RADIOLOGY_TOPIC]\", topic)\n",
        "\n",
        "    # Create the crew\n",
        "    flashcard_crew = Crew(\n",
        "        agents=[radiopaedia_researcher, content_extractor, flashcard_generator],\n",
        "        tasks=[radiopaedia_search_task, content_extraction_task, flashcard_generation_task],\n",
        "        process=Process.sequential,\n",
        "        max_rpm=MAX_RPM,\n",
        "        max_retry_limit=MAX_RETRY_LIMIT,\n",
        "        output_log_file=True,\n",
        "        verbose=True)\n",
        "\n",
        "    # Execute the crew and get results\n",
        "    result = flashcard_crew.kickoff()\n",
        "\n",
        "    # Extract and save the flashcards\n",
        "    flashcards = extract_json_from_output(result.raw)\n",
        "    qa_bank_json = \"qa_bank.json\"\n",
        "    with open(qa_bank_json, \"w\") as f:\n",
        "        json.dump(flashcards, f, indent=2)\n",
        "\n",
        "    print(f\"Generated {len(flashcards)} flashcards for '{topic}'\")\n",
        "\n",
        "    create_flashcard_ppt(\"qa_bank.json\", topic)\n",
        "\n",
        "    print('-'*50)\n",
        "    print(\"\\nFlashcard generation complete.\\n\")\n",
        "    print(\"<<<--- Open the left tab and look for your flashcard ppt file.\\n\")\n",
        "    print('-'*50)"
      ],
      "metadata": {
        "id": "vkRx-xoWxPF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ§  Time to Run the Agentic Flashcard Generator\n",
        "\n",
        "This section will launch a team of three AI agents to generate high-quality, board-style radiology flashcards based on Radiopaedia content.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ” Choose Your Topic:\n",
        "Update the `topic` variable with **any radiology topic** you want to use for flashcard generation.  \n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ“ Outputs:\n",
        "- ðŸ“½ï¸ Flashcards compiled into a PowerPoint deck: `flashcards.pptx`\n"
      ],
      "metadata": {
        "id": "MC4K2mJN5sgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with the radiology topic of interest\n",
        "topic = \"CNS lesions in HIV\"\n",
        "\n",
        "# Run the flashcards pipeline\n",
        "generate_flashcards(topic)"
      ],
      "metadata": {
        "id": "4YmvrLW25ryj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## âœ… Notebook Complete â€“ Powered by Agentic AI\n",
        "\n",
        "Youâ€™ve just completed an end-to-end demonstration of **Agentic AI in Radiology**, showcasing how multi-agent systems can streamline research, automate content extraction, and generate high-yield educational tools.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ™Œ Acknowledgments\n",
        "\n",
        "This notebook was made possible through the integration of multiple cutting-edge platforms and technologies:\n",
        "\n",
        "- **[PubMed](https://pubmed.ncbi.nlm.nih.gov/)** â€“ for sourcing peer-reviewed medical literature  \n",
        "- **[Radiopaedia](https://radiopaedia.org/)** â€“ for open-access radiology education content  \n",
        "- **[Google Gemini](https://aistudio.google.com/)** â€“ for LLM-powered reasoning and synthesis  \n",
        "- **[Apify](https://apify.com/)** â€“ for browser-based web scraping with markdown output  \n",
        "- **[CrewAI](https://github.com/joaomdmoura/crewAI)** â€“ for coordinating intelligent agent workflows  \n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ‘¨â€âš•ï¸ Authored by\n",
        "\n",
        "**Paulo Kuriki, MD**  \n",
        "Assistant Professor & Director, AI Lab / AIR-Hub  \n",
        "**UT Southwestern Medical Center**  \n",
        "\n",
        "ðŸ”— [Connect on LinkedIn](https://www.linkedin.com/in/paulokuriki/)  \n",
        "ðŸ’» [GitHub](https://github.com/paulokuriki)\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ’¬ Stay Curious. Keep Building.\n",
        "\n",
        "If this notebook inspired you to bring agentic workflows into your clinical, research, or educational practiceâ€”**you're just getting started**.\n",
        "\n",
        "Letâ€™s continue building the future of radiology, together. ðŸ§ ðŸ’¥\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "vjeoC9cU6W1i"
      }
    }
  ]
}